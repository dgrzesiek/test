{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An introduction to Convolutional Neural Networks in 3 Parts\n",
    "In this notebook we will start with 2 different threads:\n",
    "\n",
    "1. An introduction to processing images. In our previous work with images (for example the MNIST data), the images were provided to us preprocessed. So we got a nicely formated CSV file. In this thread we will learn to process actual jpg images. \n",
    "2. An introduction to convolutional networks (CNN).\n",
    "\n",
    "Once you learn the basics of these two threads, you will combine them to create a CNN that processes images. Let's get started.\n",
    "\n",
    "\n",
    "# Part 1: Dogs and Cats\n",
    "Who doesn't love dogs or cats?\n",
    "\n",
    "### from F. Chollet\n",
    "\n",
    "## Part 1 Step 1: Downloading the data\n",
    "\n",
    "The cats vs. dogs dataset that we will use isn't packaged with Keras. It was made available by Kaggle.com as part of a computer vision \n",
    "competition in late 2013, back when convnets weren't quite mainstream. You can download the original dataset at: \n",
    "`https://www.kaggle.com/c/dogs-vs-cats/data` (you will need to create a Kaggle account if you don't already have one -- don't worry, the \n",
    "process is painless).\n",
    "\n",
    "The pictures are medium-resolution color JPEGs. They look like this:\n",
    "\n",
    "![cats_vs_dogs_samples](https://s3.amazonaws.com/book.keras.io/img/ch5/cats_vs_dogs_samples.jpg)\n",
    "\n",
    "Unsurprisingly, the cats vs. dogs Kaggle competition in 2013 was won by entrants who used convnets. The best entries could achieve up to \n",
    "95% accuracy. In our own example, we will get fairly close to this accuracy (in the next section), even though we will be training our \n",
    "models on less than 10% of the data that was available to the competitors.\n",
    "This original dataset contains 25,000 images of dogs and cats (12,500 from each class) and is 543MB large (compressed). After downloading \n",
    "and uncompressing it, we will create a new dataset containing three subsets: a training set with 1000 samples of each class, a validation \n",
    "set with 500 samples of each class, and finally a test set with 500 samples of each class.\n",
    "\n",
    "Here are a few lines of code to do this:\n",
    "\n",
    "### Don't forget to change the directory names to match your file system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileExistsError",
     "evalue": "[Errno 17] File exists: '/Users/raz/data/cats_and_dogs_small'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-007196dcb630>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# store our smaller dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mbase_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/Users/raz/data/cats_and_dogs_small'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Directories for our training,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileExistsError\u001b[0m: [Errno 17] File exists: '/Users/raz/data/cats_and_dogs_small'"
     ]
    }
   ],
   "source": [
    "import os, shutil\n",
    "# The path to the directory where the original\n",
    "# dataset was uncompressed\n",
    "original_dataset_dir = '/Users/raz/data/dogTrain'\n",
    "\n",
    "# The directory where we will\n",
    "# store our smaller dataset\n",
    "base_dir = '/Users/raz/data/cats_and_dogs_small'\n",
    "os.mkdir(base_dir)\n",
    "\n",
    "# Directories for our training,\n",
    "# validation and test splits\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "os.mkdir(train_dir)\n",
    "validation_dir = os.path.join(base_dir, 'validation')\n",
    "os.mkdir(validation_dir)\n",
    "test_dir = os.path.join(base_dir, 'test')\n",
    "os.mkdir(test_dir)\n",
    "\n",
    "# Directory with our training cat pictures\n",
    "train_cats_dir = os.path.join(train_dir, 'cats')\n",
    "os.mkdir(train_cats_dir)\n",
    "\n",
    "# Directory with our training dog pictures\n",
    "train_dogs_dir = os.path.join(train_dir, 'dogs')\n",
    "os.mkdir(train_dogs_dir)\n",
    "\n",
    "# Directory with our validation cat pictures\n",
    "validation_cats_dir = os.path.join(validation_dir, 'cats')\n",
    "os.mkdir(validation_cats_dir)\n",
    "\n",
    "# Directory with our validation dog pictures\n",
    "validation_dogs_dir = os.path.join(validation_dir, 'dogs')\n",
    "os.mkdir(validation_dogs_dir)\n",
    "\n",
    "# Directory with our validation cat pictures\n",
    "test_cats_dir = os.path.join(test_dir, 'cats')\n",
    "os.mkdir(test_cats_dir)\n",
    "\n",
    "# Directory with our validation dog pictures\n",
    "test_dogs_dir = os.path.join(test_dir, 'dogs')\n",
    "os.mkdir(test_dogs_dir)\n",
    "\n",
    "# Copy first 1000 cat images to train_cats_dir\n",
    "fnames = ['cat.{}.jpg'.format(i) for i in range(1000)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(train_cats_dir, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "\n",
    "# Copy next 500 cat images to validation_cats_dir\n",
    "fnames = ['cat.{}.jpg'.format(i) for i in range(1000, 1500)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(validation_cats_dir, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "    \n",
    "# Copy next 500 cat images to test_cats_dir\n",
    "fnames = ['cat.{}.jpg'.format(i) for i in range(1500, 2000)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(test_cats_dir, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "    \n",
    "# Copy first 1000 dog images to train_dogs_dir\n",
    "fnames = ['dog.{}.jpg'.format(i) for i in range(1000)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(train_dogs_dir, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "    \n",
    "# Copy next 500 dog images to validation_dogs_dir\n",
    "fnames = ['dog.{}.jpg'.format(i) for i in range(1000, 1500)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(validation_dogs_dir, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "    \n",
    "# Copy next 500 dog images to test_dogs_dir\n",
    "fnames = ['dog.{}.jpg'.format(i) for i in range(1500, 2000)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(test_dogs_dir, fname)\n",
    "    shutil.copyfile(src, dst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1 Step 2: Data preprocessing\n",
    "\n",
    "As you already know by now, data should be formatted into appropriately pre-processed floating point tensors before being fed into our \n",
    "network. Currently, our data sits on a drive as JPEG files, so the steps for getting it into our network are roughly:\n",
    "\n",
    "* Read the picture files.\n",
    "* Decode the JPEG content to RBG grids of pixels.\n",
    "* Convert these into floating point tensors.\n",
    "* Rescale the pixel values (between 0 and 255) to the [0, 1] interval (as you know, neural networks prefer to deal with small input values).\n",
    "\n",
    "It may seem a bit daunting, but thankfully Keras has utilities to take care of these steps automatically. Keras has a module with image \n",
    "processing helper tools, located at `keras.preprocessing.image`. In particular, it contains the class `ImageDataGenerator` which allows to \n",
    "quickly set up Python generators that can automatically turn image files on disk into batches of pre-processed tensors. This is what we \n",
    "will use here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# All images will be rescaled by 1./255\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        # This is the target directory\n",
    "        train_dir,\n",
    "        # All images will be resized to 150x150\n",
    "        target_size=(150, 150),\n",
    "        batch_size=20,\n",
    "        # Since we use binary_crossentropy loss, we need binary labels\n",
    "        class_mode='binary')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        validation_dir,\n",
    "        target_size=(150, 150),\n",
    "        batch_size=20,\n",
    "        class_mode='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**note**: the generators convert the jpeg images to the `target_size`. In the example above, the images are scaled to 150x150x3.\n",
    "\n",
    "Suppose we construct a fully neural network model. We can fit our model to the data using the `train_generator` and `validation_generator`. We do it using the `fit_generator` method, the equivalent of `fit` for data generators \n",
    "like ours. It expects as first argument a Python generator that will yield batches of inputs and targets indefinitely, like ours does. \n",
    "Because the data is being generated endlessly, the generator needs to know example how many samples to draw from the generator before \n",
    "declaring an epoch over. This is the role of the `steps_per_epoch` argument: after having drawn `steps_per_epoch` batches from the \n",
    "generator, i.e. after having run for `steps_per_epoch` gradient descent steps, the fitting process will go to the next epoch. In our case, \n",
    "batches are 20-sample large, so it will take 100 batches until we see our target of 2000 samples.\n",
    "\n",
    "When using `fit_generator`, one may pass a `validation_data` argument, much like with the `fit` method. Importantly, this argument is \n",
    "allowed to be a data generator itself, but it could be a tuple of Numpy arrays as well. If you pass a generator as `validation_data`, then \n",
    "this generator is expected to yield batches of validation data endlessly, and thus you should also specify the `validation_steps` argument, \n",
    "which tells the process how many batches to draw from the validation generator for evaluation.\n",
    "\n",
    "Here's an example:\n",
    "\n",
    "\n",
    "      history = model.fit_generator(\n",
    "\t\t      train_generator,\n",
    "\t\t      steps_per_epoch=100,\n",
    "\t\t      epochs=30,\n",
    "\t\t      validation_data=validation_generator,\n",
    "\t\t      validation_steps=50)\n",
    " \n",
    "## Part 1 Step 3: create and compile a fully connected model.\n",
    "Construct a fully connected model like you did for the mnist data. The architecture should be:\n",
    "\n",
    "    _________________________________________________________________\n",
    "    Layer (type)                 Output Shape              Param #   \n",
    "    =================================================================\n",
    "    flatten_1 (Flatten)          (None, 67500)             0         \n",
    "    _________________________________________________________________\n",
    "    dense_3 (Dense)              (None, 512)               34560512  \n",
    "    _________________________________________________________________\n",
    "    dense_4 (Dense)              (None, 1)                 513       \n",
    "    =================================================================\n",
    "    Total params: 34,561,025\n",
    "    Trainable params: 34,561,025\n",
    "    Non-trainable params: 0\n",
    "    __________________________\n",
    "\n",
    "Compile the network using the following parameters:\n",
    "\n",
    " parameter | value\n",
    " :---: | :---:\n",
    " loss |'binary_crossentropy'\n",
    " optimizer| optimizers.RMSprop(lr=1e-4)\n",
    " metrics | ['acc']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "network = models.Sequential()\n",
    "network.add(layers.Flatten(input_shape=(150, 150, 3)))\n",
    "\n",
    "# YOUR WORK HERE\n",
    "\n",
    "network.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1 Step 4: fit the model \n",
    "Fit the model as described in step 2 above.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1 Step 5: evaluate the model on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoreSeg = network.evaluate_generator(validation_generator,5250)\n",
    "print(\"Accuracy = \",scoreSeg[1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That accuracy is pretty disappointing. Shortly we will see if we can do better. But first ...\n",
    "\n",
    "# Part 2: Convolutional Neural Networks \n",
    "\n",
    "## A guided tour\n",
    "\n",
    "Let's first practice what we learned in the first Keras Python Notebook\n",
    "\n",
    "## Part 2 Step 1. Load the MNIST Dataset\n",
    "First let's load the MNIST dataset from Keras into Numpy arrays called: \n",
    "\n",
    "     train_images, train_labels, test_images, test_labels\n",
    "     \n",
    "(We've done this before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 Step 2: Reshape the Data\n",
    "In the first notebook we reshaped the data into\n",
    "\n",
    "     (60000, 28 * 28)\n",
    "     \n",
    "Basically, we flattened the image. For this notebook let's retain the 2D structure and reshape it:\n",
    "\n",
    "     ((60000, 28, 28, 1))\n",
    "     \n",
    "At the same time we should also set the type to be `float32`\n",
    "\n",
    "At the end of this step you should have new values for `train_images` and `test_images`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 Step 3: Categorically Encode the Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 Step 4: Creating the Model - The ConvNet layers\n",
    "This part I will give to you. It was explained in the associated lecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "from keras import models\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 Step 5. Adding Layers\n",
    "Now we need to flatten the outputs of the ConvNet layers to the 1D representation our classifier needs.\n",
    "The classification layer will be exactly the same as that in the first notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "# ADD CLASSIFICATION LAYER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 Step 6: Compile the Model\n",
    "Now it is time to compile the model. Use the same optimizer, loss function, and accuracy metrics we used before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 Step 7. Fit the Model to the Training Data\n",
    "Use 5 epochs and a batch size of 64. Don't forget to save the history. We will also use the `fit` parameter `validation_split`. Here is what the Keras documentation says about it: \n",
    "\n",
    "> validation_split: Float between 0 and 1. Fraction of the training data to be used as validation data. The model will set apart this fraction of the training data, will not train on it, and will evaluate the loss and any model metrics on this data at the end of each epoch. The validation data is selected from the last samples in the x and y data provided, before shuffling.\n",
    "\n",
    "Let's use a validation split of 0.2\n",
    "\n",
    "We will save the intermediate results of fitting by using a variable:\n",
    "\n",
    "    history = model.fit( ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 Step 8. Run the Model on The Test Data\n",
    "Run the Model on the Test Data and print the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 Step 9. Graph The Loss and Accuracy\n",
    "Let's use Matplotlib to plot the training and validation loss side by side, as well as the training and validation accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Dogs 'n Cats with ConvNets\n",
    "This Python notebook is a slight remix of one by François Chollet for his book *Deep Learning With Python*\n",
    "\n",
    "## Previously ... \n",
    "we downloaded the data then divided it up into a set of image files inside a number of directories. Let's make sure we have those images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "base_dir = '/Users/raz/data/cats_and_dogs_small'\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "train_cats_dir = os.path.join(train_dir, 'cats')\n",
    "train_dogs_dir = os.path.join(train_dir, 'dogs')\n",
    "validation_dir = os.path.join(base_dir, 'validation')\n",
    "validation_cats_dir = os.path.join(validation_dir, 'cats')\n",
    "validation_dogs_dir = os.path.join(validation_dir, 'dogs')\n",
    "test_dir = os.path.join(base_dir, 'test')\n",
    "test_cats_dir = os.path.join(test_dir, 'cats')\n",
    "test_dogs_dir = os.path.join(test_dir, 'dogs')\n",
    "\n",
    "\n",
    "print('total training cat images:', len(os.listdir(train_cats_dir)))\n",
    "print('total training dog images:', len(os.listdir(train_dogs_dir)))\n",
    "print('total validation cat images:', len(os.listdir(validation_cats_dir)))\n",
    "print('total validation dog images:', len(os.listdir(validation_dogs_dir)))\n",
    "print('total test cat images:', len(os.listdir(test_cats_dir)))\n",
    "print('total test dog images:', len(os.listdir(test_dogs_dir)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This should print:\n",
    "    \n",
    "    total training cat images: 1000\n",
    "    total training dog images: 1000\n",
    "    total validation cat images: 500\n",
    "    total validation dog images: 500\n",
    "    total test cat images: 500\n",
    "    total test dog images: 500\n",
    "    \n",
    "## Part 3 Step 1: Building a ConvNet Model\n",
    "We've already built a small convnet for MNIST in the previous example, so you should be familiar with them. We will reuse the same general structure: our convnet will be a stack of alternated `Conv2D` (with relu activation) and `MaxPooling2D` layers. Here are the steps we would like to do:\n",
    "\n",
    "1. Create a sequential model\n",
    "2. Add a `Conv2D` layer. Use 3x3 patches and a depth of 32. The input with be 150 x 150 pixel RGB images (depth of 3)\n",
    "3. Add a `MaxPooling2D`  with a patch size of 2 x 2. \n",
    "4. Add another `Conv2D` layer. Use 3x3 patches and a depth of 64. \n",
    "5. Add a `MaxPooling2D`  with a patch size of 2 x 2. \n",
    "6. Add another `Conv2D` layer. Use 3x3 patches and a depth of 128.\n",
    "7. Add a `MaxPooling2D`  with a patch size of 2 x 2. \n",
    "8. Add another `Conv2D` layer. Use 3x3 patches and a depth of 128.\n",
    "9. Add a `MaxPooling2D`  with a patch size of 2 x 2. \n",
    "10. Finish up by flattening and adding a dense layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADD YOUR CODE HERE\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(512, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify that we did it right. \n",
    "Let's check by using the summary method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should see:\n",
    "    \n",
    "    \n",
    "\t\t_________________________________________________________________\n",
    "\t\tLayer (type)                 Output Shape              Param #   \n",
    "\t\t=================================================================\n",
    "\t\tconv2d_1 (Conv2D)            (None, 148, 148, 32)      896       \n",
    "\t\t_________________________________________________________________\n",
    "\t\tmax_pooling2d_1 (MaxPooling2 (None, 74, 74, 32)        0         \n",
    "\t\t_________________________________________________________________\n",
    "\t\tconv2d_2 (Conv2D)            (None, 72, 72, 64)        18496     \n",
    "\t\t_________________________________________________________________\n",
    "\t\tmax_pooling2d_2 (MaxPooling2 (None, 36, 36, 64)        0         \n",
    "\t\t_________________________________________________________________\n",
    "\t\tconv2d_3 (Conv2D)            (None, 34, 34, 128)       73856     \n",
    "\t\t_________________________________________________________________\n",
    "\t\tmax_pooling2d_3 (MaxPooling2 (None, 17, 17, 128)       0         \n",
    "\t\t_________________________________________________________________\n",
    "\t\tconv2d_4 (Conv2D)            (None, 15, 15, 128)       147584    \n",
    "\t\t_________________________________________________________________\n",
    "\t\tmax_pooling2d_4 (MaxPooling2 (None, 7, 7, 128)         0         \n",
    "\t\t_________________________________________________________________\n",
    "\t\tflatten_1 (Flatten)          (None, 6272)              0         \n",
    "\t\t_________________________________________________________________\n",
    "\t\tdense_1 (Dense)              (None, 512)               3211776   \n",
    "\t\t_________________________________________________________________\n",
    "\t\tdense_2 (Dense)              (None, 1)                 513       \n",
    "\t\t=================================================================\n",
    "\t\tTotal params: 3,453,121\n",
    "\t\tTrainable params: 3,453,121\n",
    "\t\tNon-trainable params: 0\n",
    "        \n",
    "## Part 3 Step 2: Compile the Model\n",
    "\n",
    "Set the parameters:\n",
    "\n",
    "* set loss to be binary_crossentropy\n",
    "* use `optimizers.RMSprop(lr=1e-4)` as the optimizer\n",
    "* for metrics use `acc`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3 Step 3: # Data Preprocessing\n",
    "Use the same data preprocessing steps we used for the original Dogs n' Cats. You should create a `train_generator` and a `validation_generator`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3 Step 4: Fit the model\n",
    "Use `fit_generator`. Don't forget to save the history.\n",
    "\n",
    "1. Use 30 epochs\n",
    "2. Each with 100 steps\n",
    "3. Use the `validation_generator` as the validation data\n",
    "4. Set the validation steps to 50.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3 Step 5: Evaluate the model using the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3 Step 6: Plot the loss and accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at those plots. \n",
    "What do they indicate? Seriously, spend a few minutes looking at them. Please.\n",
    "\n",
    "# OPTIONAL Using data augmentation\n",
    "\n",
    "This section is directly from François Chollet \n",
    "\n",
    "Overfitting is caused by having too few samples to learn from, rendering us unable to train a model able to generalize to new data. Given infinite data, our model would be exposed to every possible aspect of the data distribution at hand: we would never overfit. Data augmentation takes the approach of generating more training data from existing training samples, by \"augmenting\" the samples via a number of random transformations that yield believable-looking images. The goal is that at training time, our model would never see the exact same picture twice. This helps the model get exposed to more aspects of the data and generalize better.\n",
    "In Keras, this can be done by configuring a number of random transformations to be performed on the images read by our ImageDataGenerator instance. Let's get started with an example:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "      rotation_range=40,\n",
    "      width_shift_range=0.2,\n",
    "      height_shift_range=0.2,\n",
    "      shear_range=0.2,\n",
    "      zoom_range=0.2,\n",
    "      horizontal_flip=True,\n",
    "      fill_mode='nearest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are just a few of the options available (for more, see the Keras documentation). Let's quickly go over what we just wrote:\n",
    "\n",
    "* `rotation_range` is a value in degrees (0-180), a range within which to randomly rotate pictures.\n",
    "* `width_shift` and `height_shift` are ranges (as a fraction of total width or height) within which to randomly translate pictures \n",
    "vertically or horizontally.\n",
    "* `shear_range` is for randomly applying shearing transformations.\n",
    "* `zoom_range` is for randomly zooming inside pictures.\n",
    "* `horizontal_flip` is for randomly flipping half of the images horizontally -- relevant when there are no assumptions of horizontal \n",
    "asymmetry (e.g. real-world pictures).\n",
    "* `fill_mode` is the strategy used for filling in newly created pixels, which can appear after a rotation or a width/height shift.\n",
    "\n",
    "Let's take a look at our augmented images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "# This is module with image preprocessing utilities\n",
    "from keras.preprocessing import image\n",
    "\n",
    "fnames = [os.path.join(train_dogs_dir, fname) for fname in os.listdir(train_dogs_dir)]\n",
    "\n",
    "# We pick one image to \"augment\"\n",
    "#print(os.listdir(train_dogs_dir).index('dog.788.jpg'))\n",
    "img_path = fnames[107]\n",
    "# Read the image and resize it\n",
    "img = image.load_img(img_path, target_size=(150, 150))\n",
    "\n",
    "# Convert it to a Numpy array with shape (150, 150, 3)\n",
    "x = image.img_to_array(img)\n",
    "\n",
    "# Reshape it to (1, 150, 150, 3)\n",
    "x = x.reshape((1,) + x.shape)\n",
    "\n",
    "# The .flow() command below generates batches of randomly transformed images.\n",
    "# It will loop indefinitely, so we need to `break` the loop at some point!\n",
    "i = 0\n",
    "for batch in datagen.flow(x, batch_size=1):\n",
    "    plt.figure(i)\n",
    "    imgplot = plt.imshow(image.array_to_img(batch[0]))\n",
    "    i += 1\n",
    "    if i % 4 == 0:\n",
    "        break\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we train a new network using this data augmentation configuration, our network will never see twice the same input. However, the inputs \n",
    "that it sees are still heavily intercorrelated, since they come from a small number of original images -- we cannot produce new information, \n",
    "we can only remix existing information. As such, this might not be quite enough to completely get rid of overfitting. To further fight \n",
    "overfitting, we will also add a Dropout layer to our model using: \n",
    "\n",
    "     augmented_model.add(layers.Dropout(0.5))\n",
    "\n",
    "between the flatten layer and the densely-connected classifier. Copy your model declaration from above and add this line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile the Model\n",
    "Use the same settings as before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sweet! Here is the code for the augmented data generator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,)\n",
    "\n",
    "# Note that the validation data should not be augmented!\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        # This is the target directory\n",
    "        train_dir,\n",
    "        # All images will be resized to 150x150\n",
    "        target_size=(150, 150),\n",
    "        batch_size=32,\n",
    "        # Since we use binary_crossentropy loss, we need binary labels\n",
    "        class_mode='binary')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        validation_dir,\n",
    "        target_size=(150, 150),\n",
    "        batch_size=32,\n",
    "        class_mode='binary')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit the model\n",
    "Now we will use these new generators to fit the model.\n",
    "\n",
    "Use `fit_generator`. Don't forget to save the history.\n",
    "\n",
    "1. Use 100 epochs\n",
    "2. Each with 100 steps\n",
    "3. Use the `validation_generator` as the validation data\n",
    "4. Set the validation steps to 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's plot our results again\n",
    "One plot showing the training and validation accuracy, another showing training and validation loss.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questions\n",
    "\n",
    "1. What do these graphs show? How are they different from the graphs in the previous section?\n",
    "2. What was the point of data augmentation? \n",
    "   1. How did it help?\n",
    "   2. When would we use it?\n",
    "3. In the very first codeblock of this notebook we created training, validation and test sets. \n",
    "   1. Why do we need them?\n",
    "   2. What does each one do?\n",
    "   3. Why can't we use the training set for validation?\n",
    "4. What is a dropout layer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
